# -*- coding: utf-8 -*-
"""LinearRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10aE-d20G4YUXguGfBU4NmgNXTpsZ0bgX
"""

#making dataset
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import datasets
import matplotlib.pyplot as plt

X , y = datasets.make_regression(n_samples = 500 , n_features = 1 , noise = 20 , random_state = 101)
X_train , X_test , y_train , y_test = train_test_split(X, y  , test_size = 0.2 , random_state = 101)

fig = plt.figure(figsize=(10,10))
plt.scatter(X , y , color='b' , marker='o' , s=30)
plt.show()

print(X.shape , y.shape)

"""formaulae used in the Lienar Regression

1.Aproximation function :
     
     y = wx + b ; 
     where :
     w = weight ; b = bias

2.Calculating weights and bias gradients

    weight_gradient = (1/nummber_of_samples)*np.dot(2*training_data.Transpose, (y_predicted - ground_truth))
    bias_gradient = (1/number_of_samples) * np.sum(y_predicted-ground_truth)

3.Updating weights and bias

    weights -= learning_rate*weight_gradient
    bias -= learning_rate*bias_-gradient

"""

class LinearRegression:
    def __init__(self , learning_rate = 0.001 , n_iters = 500):
        self.learning_rate = learning_rate
        self.n_iters = n_iters
        self.weights = None
        self.bias = None
    
    def fit(self , X , y):
        #extracting number of samples = 500 , number of features = 1
        n_samples , n_features = X.shape
        #initializing weights and bias
        #initial weights and bias will be 0
        self.weights = np.zeros(n_features)
        self.bias = 0

        #implementing Gradient Descent algorithm
        for i in range(n_samples):
            #ypred = wx+b (approximation function)
            y_pred = np.dot(X , self.weights)+self.bias

            #calculating wwights and bias gradients (this tells the direction in which algo should proceed to reach the global minima)
            dw = (1/n_samples)*np.dot(2*X.T, (y_pred - y))
            db = (1/n_samples) * np.sum(y_pred-y)

            #adjusting weights and bias
            self.weights -= self.learning_rate*dw
            self.bias -= self.learning_rate*db

            ##no error function based optimazation because there is no backpropogation!
    def predict(self , X):
        return np.dot(X , self.weights)+self.bias



regressor = LinearRegression(learning_rate=0.01 , n_iters=1000)
regressor.fit(X_train , y_train)
predictions = regressor.predict(X_test)

#defining cost function
def mse(y_true , y_pred):
    return np.mean((y_true-y_pred)**2)


mse_value = mse(y_test , predictions)
print(mse_value)

#plotting the linear regression line
y_pred_line = regressor.predict(X)
cmap = plt.get_cmap('viridis')
fig = plt.figure(figsize=(10,10))
m1 = plt.scatter(X_train ,y_train , color=cmap(0.9),s=10)
m2 = plt.scatter(X_test , y_test , color=cmap(0.5) , s=10)
plt.plot(X , y_pred_line , color='black' , linewidth=2 , label='Prediction')
plt.show()

